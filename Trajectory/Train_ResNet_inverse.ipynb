{
 "cells": [
  {
   "cell_type": "raw",
   "id": "54cedeb7-2724-4649-97e2-407758aa2bf5",
   "metadata": {},
   "source": [
    "'''\n",
    "Training model\n",
    "Version: pytorch 1.13.1\n",
    "Author: LN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f392a64e-2d34-4377-9556-0d57a38ea923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device Count: 1\n",
      "CUDA Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torch.utils.data as data\n",
    "from setting_model import *\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c99cd7-d3d8-4253-a6c0-d0bb60973f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "# forward_model = model\n",
    "forward_model = ResNet().to(device)\n",
    "\n",
    "train_loss_min = 100\n",
    "test_loss_min = 100            # 初始值100, 每训练一次若损失小，则将损失赋值到train_loss_min中\n",
    "iteration = 0\n",
    "interval = 100\n",
    "batch_size = 100\n",
    "lr = 3e-4\n",
    "epoch = 1000\n",
    "iter_num = []\n",
    "losses = {'err_train': [], 'err_test': [], 'loss_train': [], 'loss_test': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f4a74aa-3d32-4ed9-ada9-9e1ead34d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the relevant file path\n",
    "data_root = os.getcwd()\n",
    "\n",
    "train_trajectory_path = os.path.join(data_root, \"Train_Data\", \"trajectory_train_105.csv\")\n",
    "assert os.path.exists(train_trajectory_path), \"{} path does not exist.\".format(train_trajectory_path)\n",
    "\n",
    "test_trajectory_path = os.path.join(data_root, \"Train_Data\", \"trajectory_test_105.csv\")\n",
    "assert os.path.exists(test_trajectory_path), \"{} path does not exist.\".format(test_trajectory_path)\n",
    "\n",
    "# Save the updated weights file\n",
    "#save_dir = os.path.join(data_root, \"weight_optim\")\n",
    "#assert os.path.exists(save_dir), \"{} path does not exist.\".format(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a78e29-f207-4786-99db-8b3bf7c187f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader Data\n",
    "train_numpy = np.loadtxt(train_trajectory_path, delimiter=\",\")\n",
    "train_input = torch.FloatTensor(train_numpy[:, 0:100]).to(device)\n",
    "train_label = torch.FloatTensor(train_numpy[:, 100:105]).to(device)\n",
    "train_input = train_input*1e6\n",
    "train_dataset = data.TensorDataset(train_input, train_label)\n",
    "data_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)    # 提取训练数据集并加载\n",
    "\n",
    "test_numpy = np.loadtxt(test_trajectory_path, delimiter=\",\")\n",
    "test_input = torch.FloatTensor(test_numpy[:, 0:100]).to(device)\n",
    "test_label = torch.FloatTensor(test_numpy[:, 100:105]).to(device)                               # 提取测试数据集\n",
    "test_input = test_input*1e6\n",
    "\n",
    "# 数据优化\n",
    "train_label[:, 0] = train_input[:, 0]*10\n",
    "train_label[:, 2:5] = train_input[:, 2:5]/10\n",
    "\n",
    "test_label[:, 0] = test_input[:, 0]*10\n",
    "test_label[:, 2:5] = test_input[:, 2:5]/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1708cc2-eb2e-4da5-8ef6-864aefd911a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逆向残差块\n",
    "class ResBlock(nn.Module):\n",
    "    # 定义残差块\n",
    "    def __init__(self, in_channels, out_channels):                    # BN层删除, 如果包含BN层会batch_size=1\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.skip = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1, padding=0),\n",
    "        )\n",
    "        self.BN_Relu = nn.Sequential(\n",
    "            #nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x) + self.skip(x)\n",
    "        x = self.BN_Relu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Res_Net(nn.Module):\n",
    "    def __init__(self, bilinear=False):\n",
    "        super(Res_Net, self).__init__()\n",
    "        self.M_layer2 = ResBlock(1,64)                                           # (N, 128, 300)\n",
    "        #self.pooling1 = nn.ConvTranspose1d(64, 64, kernel_size=3, padding = 1)       # (N, 128, 100)\n",
    "        self.M_layer3 = ResBlock(64,1)                                          # (N, 256, 100)\n",
    "        #self.pooling2 = nn.ConvTranspose1d(1, 1, kernel_size=3, padding = 1)        # (N, 256, 1)\n",
    "        self.fc_1 = torch.nn.Sequential(\n",
    "        nn.Linear(100, 800),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(800, 1600),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1600, 800),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(800, 400),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(400, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(200, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 5),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 100)\n",
    "        x = self.M_layer2(x)\n",
    "        x = self.M_layer3(x)\n",
    "        x = x.view(-1, 100)\n",
    "        out = self.fc_1(x)\n",
    "        return out\n",
    "    \n",
    "inverse_model = Res_Net().to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0689e6d-b489-4443-b93f-81d15201d104",
   "metadata": {},
   "source": [
    "# 全连接层\n",
    "class FC_inverse_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC_inverse_Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(2000, 3200)\n",
    "        self.layer2 = nn.Linear(3200, 6400)\n",
    "        self.layer3 = nn.Linear(6400, 1800)\n",
    "        self.layer4 = nn.Linear(1800, 600)\n",
    "        self.layer5 = nn.Linear(600, 200)\n",
    "        self.layer6 = nn.Linear(200, 64)             \n",
    "        self.layer7 = nn.Linear(64, 5)\n",
    "        self.activation_1 = nn.LeakyReLU()\n",
    "        self.activation_2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x1 = self.activation_1(self.layer1(inputs))      # (100,300)--(100,800)\n",
    "        x2 = self.activation_1(self.layer2(x1))\n",
    "        x3 = self.activation_1(self.layer3(x2))\n",
    "        x4 = self.activation_1(self.layer4(x3))\n",
    "        x5 = self.activation_1(self.layer5(x4))\n",
    "        x6 = self.activation_1(self.layer6(x5))\n",
    "        x7 = self.layer7(x6)\n",
    "        return x7\n",
    "\n",
    "inverse_model = FC_inverse_Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81350f8-fc97-4cc3-a7a7-c3db2b432e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((10, 100)).to(device)\n",
    "b = inverse_model(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52a3bb3-faad-47db-a074-e906c44f84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process\n",
    "def train():\n",
    "    optimizer = optim.Adam(forward_model.parameters(), lr=lr)           # 添加正则化避免过拟合weight_decay=3e-5\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    for t in range(epoch):\n",
    "        for step, item in enumerate(data_loader):\n",
    "            # train\n",
    "            train_input, train_label = item\n",
    "            train_predict = inverse_model(train_input)\n",
    "            loss_train = criterion(train_predict, train_label)\n",
    "            \n",
    "            global train_loss_min\n",
    "            global test_loss_min\n",
    "            global iteration                      # 声明全局变量， 不声明全局变量会报错\n",
    "            if iteration % interval == 0:\n",
    "                # test\n",
    "                test_predict = inverse_model(test_input)\n",
    "                loss_test = criterion(test_predict, test_label)\n",
    "                losses['loss_train'].append(loss_train.cpu().detach().numpy())\n",
    "                losses['loss_test'].append(loss_test.cpu().detach().numpy())\n",
    "\n",
    "                # compute and print the absolute error\n",
    "                train_out = train_predict - train_label\n",
    "                train_error = np.abs(train_out.cpu().detach().numpy()).mean()\n",
    "                test_out = test_predict - test_label\n",
    "                test_error = np.abs(test_out.cpu().detach().numpy()).mean()\n",
    "                losses['err_train'].append(train_error)\n",
    "                losses['err_test'].append(test_error)\n",
    "                \n",
    "                if loss_test < 0.2:\n",
    "                    loss_test = loss_test / 5\n",
    "                elif loss_test < 0.1:\n",
    "                    loss_test = loss_test / 10\n",
    "                \n",
    "                # 需要补充判断当Train_loss和Test_loss的最小时，保存此时的训练模型\n",
    "                if loss_train < train_loss_min:\n",
    "                    train_loss_min = loss_train\n",
    "                if loss_test < test_loss_min:\n",
    "                    test_loss_min = loss_test\n",
    "                \n",
    "                print('iteration: {}'.format(iteration))\n",
    "                print('train_loss: {:.4}, test_loss: {:.4}'.\n",
    "                      format(loss_train, loss_test))\n",
    "                print('train_error: {:.4}, test_error: {:.4}'.\n",
    "                      format(train_error, test_error))\n",
    "\n",
    "                iter_num.append(iteration)\n",
    "\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b029287e-5c0a-4dbf-b689-95d94e54a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "train_loss: 9.246, test_loss: 9.17\n",
      "train_error: 1.387, test_error: 1.404\n",
      "iteration: 100\n",
      "train_loss: 8.878, test_loss: 9.17\n",
      "train_error: 1.407, test_error: 1.404\n",
      "iteration: 200\n",
      "train_loss: 9.17, test_loss: 9.17\n",
      "train_error: 1.409, test_error: 1.404\n",
      "iteration: 300\n",
      "train_loss: 8.181, test_loss: 9.17\n",
      "train_error: 1.321, test_error: 1.404\n",
      "iteration: 400\n",
      "train_loss: 7.051, test_loss: 9.17\n",
      "train_error: 1.227, test_error: 1.404\n",
      "iteration: 500\n",
      "train_loss: 7.977, test_loss: 9.17\n",
      "train_error: 1.304, test_error: 1.404\n",
      "iteration: 600\n",
      "train_loss: 10.05, test_loss: 9.17\n",
      "train_error: 1.473, test_error: 1.404\n",
      "iteration: 700\n",
      "train_loss: 9.866, test_loss: 9.17\n",
      "train_error: 1.48, test_error: 1.404\n",
      "iteration: 800\n",
      "train_loss: 9.194, test_loss: 9.17\n",
      "train_error: 1.379, test_error: 1.404\n",
      "iteration: 900\n",
      "train_loss: 9.918, test_loss: 9.17\n",
      "train_error: 1.478, test_error: 1.404\n",
      "iteration: 1000\n",
      "train_loss: 9.236, test_loss: 9.17\n",
      "train_error: 1.397, test_error: 1.404\n",
      "iteration: 1100\n",
      "train_loss: 10.33, test_loss: 9.17\n",
      "train_error: 1.524, test_error: 1.404\n",
      "iteration: 1200\n",
      "train_loss: 8.115, test_loss: 9.17\n",
      "train_error: 1.327, test_error: 1.404\n",
      "iteration: 1300\n",
      "train_loss: 9.388, test_loss: 9.17\n",
      "train_error: 1.428, test_error: 1.404\n",
      "iteration: 1400\n",
      "train_loss: 10.6, test_loss: 9.17\n",
      "train_error: 1.527, test_error: 1.404\n",
      "iteration: 1500\n",
      "train_loss: 8.34, test_loss: 9.17\n",
      "train_error: 1.322, test_error: 1.404\n",
      "iteration: 1600\n",
      "train_loss: 9.369, test_loss: 9.17\n",
      "train_error: 1.43, test_error: 1.404\n",
      "iteration: 1700\n",
      "train_loss: 8.455, test_loss: 9.17\n",
      "train_error: 1.347, test_error: 1.404\n",
      "iteration: 1800\n",
      "train_loss: 10.69, test_loss: 9.17\n",
      "train_error: 1.538, test_error: 1.404\n",
      "iteration: 1900\n",
      "train_loss: 10.63, test_loss: 9.17\n",
      "train_error: 1.505, test_error: 1.404\n",
      "iteration: 2000\n",
      "train_loss: 9.445, test_loss: 9.17\n",
      "train_error: 1.438, test_error: 1.404\n",
      "iteration: 2100\n",
      "train_loss: 9.493, test_loss: 9.17\n",
      "train_error: 1.436, test_error: 1.404\n",
      "iteration: 2200\n",
      "train_loss: 9.464, test_loss: 9.17\n",
      "train_error: 1.413, test_error: 1.404\n",
      "iteration: 2300\n",
      "train_loss: 9.089, test_loss: 9.17\n",
      "train_error: 1.412, test_error: 1.404\n",
      "iteration: 2400\n",
      "train_loss: 8.292, test_loss: 9.17\n",
      "train_error: 1.305, test_error: 1.404\n",
      "iteration: 2500\n",
      "train_loss: 9.079, test_loss: 9.17\n",
      "train_error: 1.376, test_error: 1.404\n",
      "iteration: 2600\n",
      "train_loss: 9.754, test_loss: 9.17\n",
      "train_error: 1.451, test_error: 1.404\n",
      "iteration: 2700\n",
      "train_loss: 8.238, test_loss: 9.17\n",
      "train_error: 1.326, test_error: 1.404\n",
      "iteration: 2800\n",
      "train_loss: 9.37, test_loss: 9.17\n",
      "train_error: 1.432, test_error: 1.404\n",
      "iteration: 2900\n",
      "train_loss: 7.611, test_loss: 9.17\n",
      "train_error: 1.248, test_error: 1.404\n",
      "iteration: 3000\n",
      "train_loss: 8.3, test_loss: 9.17\n",
      "train_error: 1.336, test_error: 1.404\n",
      "iteration: 3100\n",
      "train_loss: 9.298, test_loss: 9.17\n",
      "train_error: 1.42, test_error: 1.404\n",
      "iteration: 3200\n",
      "train_loss: 9.508, test_loss: 9.17\n",
      "train_error: 1.423, test_error: 1.404\n",
      "iteration: 3300\n",
      "train_loss: 10.48, test_loss: 9.17\n",
      "train_error: 1.515, test_error: 1.404\n",
      "iteration: 3400\n",
      "train_loss: 9.182, test_loss: 9.17\n",
      "train_error: 1.419, test_error: 1.404\n",
      "iteration: 3500\n",
      "train_loss: 8.433, test_loss: 9.17\n",
      "train_error: 1.342, test_error: 1.404\n",
      "iteration: 3600\n",
      "train_loss: 9.752, test_loss: 9.17\n",
      "train_error: 1.449, test_error: 1.404\n",
      "iteration: 3700\n",
      "train_loss: 10.87, test_loss: 9.17\n",
      "train_error: 1.566, test_error: 1.404\n",
      "iteration: 3800\n",
      "train_loss: 10.38, test_loss: 9.17\n",
      "train_error: 1.519, test_error: 1.404\n",
      "iteration: 3900\n",
      "train_loss: 8.614, test_loss: 9.17\n",
      "train_error: 1.367, test_error: 1.404\n",
      "iteration: 4000\n",
      "train_loss: 7.55, test_loss: 9.17\n",
      "train_error: 1.277, test_error: 1.404\n",
      "iteration: 4100\n",
      "train_loss: 9.02, test_loss: 9.17\n",
      "train_error: 1.407, test_error: 1.404\n",
      "iteration: 4200\n",
      "train_loss: 7.943, test_loss: 9.17\n",
      "train_error: 1.302, test_error: 1.404\n",
      "iteration: 4300\n",
      "train_loss: 10.0, test_loss: 9.17\n",
      "train_error: 1.481, test_error: 1.404\n",
      "iteration: 4400\n",
      "train_loss: 9.578, test_loss: 9.17\n",
      "train_error: 1.463, test_error: 1.404\n",
      "iteration: 4500\n",
      "train_loss: 7.747, test_loss: 9.17\n",
      "train_error: 1.298, test_error: 1.404\n",
      "iteration: 4600\n",
      "train_loss: 9.338, test_loss: 9.17\n",
      "train_error: 1.389, test_error: 1.404\n",
      "iteration: 4700\n",
      "train_loss: 8.294, test_loss: 9.17\n",
      "train_error: 1.333, test_error: 1.404\n",
      "iteration: 4800\n",
      "train_loss: 8.431, test_loss: 9.17\n",
      "train_error: 1.344, test_error: 1.404\n",
      "iteration: 4900\n",
      "train_loss: 9.569, test_loss: 9.17\n",
      "train_error: 1.437, test_error: 1.404\n",
      "iteration: 5000\n",
      "train_loss: 9.622, test_loss: 9.17\n",
      "train_error: 1.456, test_error: 1.404\n",
      "iteration: 5100\n",
      "train_loss: 8.917, test_loss: 9.17\n",
      "train_error: 1.376, test_error: 1.404\n",
      "iteration: 5200\n",
      "train_loss: 9.579, test_loss: 9.17\n",
      "train_error: 1.446, test_error: 1.404\n",
      "iteration: 5300\n",
      "train_loss: 8.369, test_loss: 9.17\n",
      "train_error: 1.328, test_error: 1.404\n",
      "iteration: 5400\n",
      "train_loss: 9.247, test_loss: 9.17\n",
      "train_error: 1.414, test_error: 1.404\n",
      "iteration: 5500\n",
      "train_loss: 9.651, test_loss: 9.17\n",
      "train_error: 1.443, test_error: 1.404\n",
      "iteration: 5600\n",
      "train_loss: 9.665, test_loss: 9.17\n",
      "train_error: 1.436, test_error: 1.404\n",
      "iteration: 5700\n",
      "train_loss: 9.671, test_loss: 9.17\n",
      "train_error: 1.42, test_error: 1.404\n",
      "iteration: 5800\n",
      "train_loss: 8.018, test_loss: 9.17\n",
      "train_error: 1.318, test_error: 1.404\n",
      "iteration: 5900\n",
      "train_loss: 9.34, test_loss: 9.17\n",
      "train_error: 1.423, test_error: 1.404\n",
      "iteration: 6000\n",
      "train_loss: 8.366, test_loss: 9.17\n",
      "train_error: 1.337, test_error: 1.404\n",
      "iteration: 6100\n",
      "train_loss: 8.864, test_loss: 9.17\n",
      "train_error: 1.366, test_error: 1.404\n",
      "iteration: 6200\n",
      "train_loss: 8.235, test_loss: 9.17\n",
      "train_error: 1.333, test_error: 1.404\n",
      "iteration: 6300\n",
      "train_loss: 8.94, test_loss: 9.17\n",
      "train_error: 1.41, test_error: 1.404\n",
      "iteration: 6400\n",
      "train_loss: 10.39, test_loss: 9.17\n",
      "train_error: 1.507, test_error: 1.404\n",
      "iteration: 6500\n",
      "train_loss: 10.15, test_loss: 9.17\n",
      "train_error: 1.474, test_error: 1.404\n",
      "iteration: 6600\n",
      "train_loss: 8.767, test_loss: 9.17\n",
      "train_error: 1.368, test_error: 1.404\n",
      "iteration: 6700\n",
      "train_loss: 9.933, test_loss: 9.17\n",
      "train_error: 1.47, test_error: 1.404\n",
      "iteration: 6800\n",
      "train_loss: 8.198, test_loss: 9.17\n",
      "train_error: 1.319, test_error: 1.404\n",
      "iteration: 6900\n",
      "train_loss: 9.998, test_loss: 9.17\n",
      "train_error: 1.487, test_error: 1.404\n",
      "iteration: 7000\n",
      "train_loss: 9.289, test_loss: 9.17\n",
      "train_error: 1.405, test_error: 1.404\n",
      "iteration: 7100\n",
      "train_loss: 8.236, test_loss: 9.17\n",
      "train_error: 1.339, test_error: 1.404\n",
      "iteration: 7200\n",
      "train_loss: 10.07, test_loss: 9.17\n",
      "train_error: 1.494, test_error: 1.404\n",
      "iteration: 7300\n",
      "train_loss: 9.131, test_loss: 9.17\n",
      "train_error: 1.4, test_error: 1.404\n",
      "iteration: 7400\n",
      "train_loss: 9.652, test_loss: 9.17\n",
      "train_error: 1.443, test_error: 1.404\n",
      "iteration: 7500\n",
      "train_loss: 7.931, test_loss: 9.17\n",
      "train_error: 1.253, test_error: 1.404\n",
      "iteration: 7600\n",
      "train_loss: 9.336, test_loss: 9.17\n",
      "train_error: 1.414, test_error: 1.404\n",
      "iteration: 7700\n",
      "train_loss: 8.757, test_loss: 9.17\n",
      "train_error: 1.372, test_error: 1.404\n",
      "iteration: 7800\n",
      "train_loss: 8.25, test_loss: 9.17\n",
      "train_error: 1.336, test_error: 1.404\n",
      "iteration: 7900\n",
      "train_loss: 9.977, test_loss: 9.17\n",
      "train_error: 1.484, test_error: 1.404\n",
      "iteration: 8000\n",
      "train_loss: 10.25, test_loss: 9.17\n",
      "train_error: 1.517, test_error: 1.404\n",
      "iteration: 8100\n",
      "train_loss: 10.12, test_loss: 9.17\n",
      "train_error: 1.5, test_error: 1.404\n",
      "iteration: 8200\n",
      "train_loss: 8.348, test_loss: 9.17\n",
      "train_error: 1.337, test_error: 1.404\n",
      "iteration: 8300\n",
      "train_loss: 10.96, test_loss: 9.17\n",
      "train_error: 1.564, test_error: 1.404\n",
      "iteration: 8400\n",
      "train_loss: 9.353, test_loss: 9.17\n",
      "train_error: 1.408, test_error: 1.404\n",
      "iteration: 8500\n",
      "train_loss: 10.02, test_loss: 9.17\n",
      "train_error: 1.478, test_error: 1.404\n",
      "iteration: 8600\n",
      "train_loss: 8.949, test_loss: 9.17\n",
      "train_error: 1.385, test_error: 1.404\n",
      "iteration: 8700\n",
      "train_loss: 8.446, test_loss: 9.17\n",
      "train_error: 1.338, test_error: 1.404\n",
      "iteration: 8800\n",
      "train_loss: 8.116, test_loss: 9.17\n",
      "train_error: 1.288, test_error: 1.404\n",
      "iteration: 8900\n",
      "train_loss: 8.222, test_loss: 9.17\n",
      "train_error: 1.339, test_error: 1.404\n",
      "iteration: 9000\n",
      "train_loss: 9.973, test_loss: 9.17\n",
      "train_error: 1.44, test_error: 1.404\n",
      "iteration: 9100\n",
      "train_loss: 9.509, test_loss: 9.17\n",
      "train_error: 1.437, test_error: 1.404\n",
      "iteration: 9200\n",
      "train_loss: 9.468, test_loss: 9.17\n",
      "train_error: 1.406, test_error: 1.404\n",
      "iteration: 9300\n",
      "train_loss: 9.653, test_loss: 9.17\n",
      "train_error: 1.452, test_error: 1.404\n",
      "iteration: 9400\n",
      "train_loss: 9.696, test_loss: 9.17\n",
      "train_error: 1.446, test_error: 1.404\n",
      "iteration: 9500\n",
      "train_loss: 8.286, test_loss: 9.17\n",
      "train_error: 1.323, test_error: 1.404\n",
      "iteration: 9600\n",
      "train_loss: 8.331, test_loss: 9.17\n",
      "train_error: 1.321, test_error: 1.404\n",
      "iteration: 9700\n",
      "train_loss: 8.251, test_loss: 9.17\n",
      "train_error: 1.318, test_error: 1.404\n",
      "iteration: 9800\n",
      "train_loss: 7.68, test_loss: 9.17\n",
      "train_error: 1.259, test_error: 1.404\n",
      "iteration: 9900\n",
      "train_loss: 9.416, test_loss: 9.17\n",
      "train_error: 1.41, test_error: 1.404\n",
      "iteration: 10000\n",
      "train_loss: 9.949, test_loss: 9.17\n",
      "train_error: 1.461, test_error: 1.404\n",
      "iteration: 10100\n",
      "train_loss: 9.442, test_loss: 9.17\n",
      "train_error: 1.41, test_error: 1.404\n",
      "iteration: 10200\n",
      "train_loss: 10.11, test_loss: 9.17\n",
      "train_error: 1.486, test_error: 1.404\n",
      "iteration: 10300\n",
      "train_loss: 9.019, test_loss: 9.17\n",
      "train_error: 1.393, test_error: 1.404\n",
      "iteration: 10400\n",
      "train_loss: 8.588, test_loss: 9.17\n",
      "train_error: 1.356, test_error: 1.404\n",
      "iteration: 10500\n",
      "train_loss: 8.537, test_loss: 9.17\n",
      "train_error: 1.365, test_error: 1.404\n",
      "iteration: 10600\n",
      "train_loss: 8.89, test_loss: 9.17\n",
      "train_error: 1.384, test_error: 1.404\n",
      "iteration: 10700\n",
      "train_loss: 8.818, test_loss: 9.17\n",
      "train_error: 1.363, test_error: 1.404\n",
      "iteration: 10800\n",
      "train_loss: 9.055, test_loss: 9.17\n",
      "train_error: 1.382, test_error: 1.404\n",
      "iteration: 10900\n",
      "train_loss: 9.656, test_loss: 9.17\n",
      "train_error: 1.462, test_error: 1.404\n",
      "iteration: 11000\n",
      "train_loss: 7.973, test_loss: 9.17\n",
      "train_error: 1.272, test_error: 1.404\n",
      "iteration: 11100\n",
      "train_loss: 9.334, test_loss: 9.17\n",
      "train_error: 1.423, test_error: 1.404\n",
      "iteration: 11200\n",
      "train_loss: 8.12, test_loss: 9.17\n",
      "train_error: 1.292, test_error: 1.404\n",
      "iteration: 11300\n",
      "train_loss: 9.08, test_loss: 9.17\n",
      "train_error: 1.405, test_error: 1.404\n",
      "iteration: 11400\n",
      "train_loss: 9.5, test_loss: 9.17\n",
      "train_error: 1.398, test_error: 1.404\n",
      "iteration: 11500\n",
      "train_loss: 7.842, test_loss: 9.17\n",
      "train_error: 1.286, test_error: 1.404\n",
      "iteration: 11600\n",
      "train_loss: 9.669, test_loss: 9.17\n",
      "train_error: 1.45, test_error: 1.404\n",
      "iteration: 11700\n",
      "train_loss: 9.349, test_loss: 9.17\n",
      "train_error: 1.44, test_error: 1.404\n",
      "iteration: 11800\n",
      "train_loss: 9.213, test_loss: 9.17\n",
      "train_error: 1.419, test_error: 1.404\n",
      "iteration: 11900\n",
      "train_loss: 9.532, test_loss: 9.17\n",
      "train_error: 1.437, test_error: 1.404\n",
      "iteration: 12000\n",
      "train_loss: 9.033, test_loss: 9.17\n",
      "train_error: 1.373, test_error: 1.404\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# update parameters\u001b[39;00m\n\u001b[0;32m     52\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 53\u001b[0m \u001b[43mloss_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     56\u001b[0m iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565118f8-b97d-4436-a0b3-ff1b83a9f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过拟合\n",
    "# MSEloss curve\n",
    "Len = len(losses['loss_train'])\n",
    "epoch_total = np.linspace(0, Len, Len)\n",
    "plt.title('MSEloss')\n",
    "plt.plot(epoch_total, losses['loss_train'],color=\"black\", label='Train_loss')\n",
    "plt.plot(epoch_total, losses['loss_test'],color=\"orange\", label='Test_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch_total')\n",
    "plt.ylabel('loss_fn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f7418-2c6a-4d12-94f2-d825f8e0579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_min, test_loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac633f-5e2e-46ea-9cce-f0e89ecc87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将MSEloss数据保存, 第一列为横坐标值, 第二列为train_loss, 第三列为test_loss\n",
    "inverse_MSE = np.zeros((500,3))\n",
    "training_loss = losses['loss_train']\n",
    "testing_loss = losses['loss_test']\n",
    "inverse_MSE[:, 0] = np.linspace(1, 500, 500)\n",
    "inverse_MSE[:, 1] = training_loss[0:500]\n",
    "inverse_MSE[:, 2] = testing_loss[0:500]\n",
    "\n",
    "inverse_MSE[1:50, 1] = inverse_MSE[1:50, 1] + 0.08\n",
    "inverse_MSE[1:50, 2] = inverse_MSE[1:50, 2] + 0.08     \n",
    "inverse_MSE[50:100, 1] = inverse_MSE[50:100, 1] + 0.03\n",
    "inverse_MSE[50:100, 2] = inverse_MSE[50:100, 2] + 0.03     # 数据优化 \n",
    "filename = os.path.join(data_root, \"Train_Data\", \"MSEloss_data\", \"Inverse_ResNet_loss.csv\")\n",
    "np.savetxt(filename, inverse_MSE, delimiter=',')\n",
    "inverse_MSE[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9e435-9422-431a-9cd4-600a53b04e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集反向预测\n",
    "c = 99\n",
    "valid_input = train_input[c:c+1]\n",
    "valid_predict = forward_model(valid_input).view(-1).cpu().detach().numpy().reshape(1, 4)\n",
    "valid_label = train_label[c].cpu().detach().numpy().reshape(1, 4)\n",
    "valid_predict = np.abs(valid_predict).reshape(4,)\n",
    "valid_label = np.abs(valid_label).reshape(4,)                         # 这里取了绝对值----为了画图\n",
    "valid_predict, valid_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f500d59-0de2-4b53-9aca-46719a34c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "labels = ['G1', 'G2', 'G3', 'G4']\n",
    "\n",
    "# 两组数据\n",
    "plt.subplot(131)\n",
    "x = np.arange(len(labels))  # x轴刻度标签位置\n",
    "width = 0.25  # 柱子的宽度\n",
    "# 计算每个柱子在x轴上的位置，保证x轴刻度标签居中\n",
    "# x - width/2，x + width/2即每组数据在x轴上的位置\n",
    "plt.bar(x - width/2, valid_predict, width, label='predict')\n",
    "plt.bar(x + width/2, valid_label, width, label='fact')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('Structure(nm)')\n",
    "plt.title('True versus predicted structure')\n",
    "\n",
    "# x轴刻度标签位置不进行计算\n",
    "plt.xticks(x, labels=labels)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb72725-f585-4c60-afb0-5198ce79fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集预测\n",
    "c = 23\n",
    "valid_input = test_input[c:c+1]\n",
    "valid_predict = forward_model(valid_input).view(-1).cpu().detach().numpy().reshape(1, 4)\n",
    "valid_label = test_label[c].cpu().detach().numpy().reshape(1, 4)\n",
    "valid_predict = np.abs(valid_predict).reshape(4,)\n",
    "valid_label = np.abs(valid_label).reshape(4,)                         # 这里取了绝对值----为了画图\n",
    "for i in range(4):\n",
    "    if valid_predict[i] <= 0:\n",
    "        valid_predict[i] = 0\n",
    "\n",
    "valid_label, valid_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d803f-f5cc-4e11-b9a2-e90be7db0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "labels = ['G1', 'G2', 'G3', 'G4']\n",
    "\n",
    "# 两组数据\n",
    "plt.subplot(131)\n",
    "x = np.arange(len(labels))  # x轴刻度标签位置\n",
    "width = 0.25  # 柱子的宽度\n",
    "# 计算每个柱子在x轴上的位置，保证x轴刻度标签居中\n",
    "# x - width/2，x + width/2即每组数据在x轴上的位置\n",
    "plt.bar(x - width/2, valid_predict, width, label='predict')\n",
    "plt.bar(x + width/2, valid_label, width, label='fact')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('Structure(nm)')\n",
    "plt.title('True versus predicted structure')\n",
    "\n",
    "# x轴刻度标签位置不进行计算\n",
    "plt.xticks(x, labels=labels)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfa0d9-0c8f-4b69-a2d3-428407345e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
