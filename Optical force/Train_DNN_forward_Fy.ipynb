{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ec324430-32e9-464b-99b0-246fa368976b",
   "metadata": {},
   "source": [
    "'''\n",
    "Training model\n",
    "\n",
    "Version: pytorch 1.13.1\n",
    "Author: LN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d989fc4a-2f0c-47e9-8dc2-7f336f0439ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device Count: 1\n",
      "CUDA Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torch.utils.data as data\n",
    "from setting_model import *\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9ff6c2-01bb-4a7b-9519-74ed3b737ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "# forward_model = model\n",
    "forward_model = FC_Net().to(device)\n",
    "\n",
    "iteration = 0\n",
    "interval = 100\n",
    "batch_size = 20                 # 修改\n",
    "lr = 3e-4\n",
    "epoch = 2000\n",
    "iter_num = []\n",
    "losses = {'err_train': [], 'err_test': [], 'loss_train': [], 'loss_test': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3f9bd2-084f-4b85-b437-9f47a7be72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the relevant file path\n",
    "data_root = os.getcwd()\n",
    "bo_len_path = os.path.join(data_root, \"Train_Data_Fig4\", \"X.csv\")\n",
    "assert os.path.exists(bo_len_path), \"{} path does not exist.\".format(bo_len_path)                  # assert function\n",
    "\n",
    "train_spectrum_path = os.path.join(data_root, \"Train_Data_Fig4\", \"train_680.csv\")\n",
    "assert os.path.exists(train_spectrum_path), \"{} path does not exist.\".format(train_spectrum_path)\n",
    "\n",
    "test_spectrum_path = os.path.join(data_root, \"Train_Data_Fig4\", \"test_77.csv\")\n",
    "assert os.path.exists(test_spectrum_path), \"{} path does not exist.\".format(test_spectrum_path)\n",
    "\n",
    "# Save the updated weights file\n",
    "#save_dir = os.path.join(data_root, \"weight_optim\")\n",
    "#assert os.path.exists(save_dir), \"{} path does not exist.\".format(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87ae1a4-4bce-4592-b5ed-b006c68c9c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader Data\n",
    "train_numpy = np.loadtxt(train_spectrum_path, delimiter=\",\")\n",
    "train_input = torch.FloatTensor(train_numpy[:, 600:603]).to(device)\n",
    "train_label = torch.FloatTensor(train_numpy[:, 300:600]).to(device)\n",
    "train_dataset = data.TensorDataset(train_input, train_label)\n",
    "data_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)    # 提取训练数据集并加载\n",
    "\n",
    "test_numpy = np.loadtxt(test_spectrum_path, delimiter=\",\")\n",
    "test_input = torch.FloatTensor(test_numpy[:, 600:603]).to(device)\n",
    "test_label = torch.FloatTensor(test_numpy[:, 300:600]).to(device)                               # 提取测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a319d3-f852-4296-a160-ac4721316277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([680, 3]), torch.Size([77, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape, test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ae09ad-421c-44f3-b6fd-73c28428ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process\n",
    "def train():\n",
    "    optimizer = optim.Adam(forward_model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    for t in range(epoch):\n",
    "        for step, item in enumerate(data_loader):\n",
    "            # train\n",
    "            train_input, train_label = item\n",
    "            train_predict = forward_model(train_input)\n",
    "            loss_train = criterion(train_predict, train_label)\n",
    "            \n",
    "            global iteration                      # 声明全局变量， 不声明全局变量会报错\n",
    "            if iteration % interval == 0:\n",
    "                # test\n",
    "                test_predict = forward_model(test_input)\n",
    "                loss_test = criterion(test_predict, test_label)\n",
    "                losses['loss_train'].append(loss_train.cpu().detach().numpy())\n",
    "                losses['loss_test'].append(loss_test.cpu().detach().numpy())\n",
    "\n",
    "                # compute and print the absolute error\n",
    "                train_out = train_predict - train_label\n",
    "                train_error = np.abs(train_out.cpu().detach().numpy()).mean()\n",
    "                test_out = test_predict - test_label\n",
    "                test_error = np.abs(test_out.cpu().detach().numpy()).mean()\n",
    "                losses['err_train'].append(train_error)\n",
    "                losses['err_test'].append(test_error)\n",
    "\n",
    "                print('iteration: {}'.format(iteration))\n",
    "                print('train_loss: {:.4}, test_loss: {:.4}'.\n",
    "                      format(loss_train, loss_test))\n",
    "                print('train_error: {:.4}, test_error: {:.4}'.\n",
    "                      format(train_error, test_error))\n",
    "\n",
    "                iter_num.append(iteration)\n",
    "\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de81bae3-736f-40ed-abb4-ce4ef46db845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "train_loss: 0.2346, test_loss: 0.1717\n",
      "train_error: 0.2774, test_error: 0.2193\n",
      "iteration: 100\n",
      "train_loss: 0.03766, test_loss: 0.03489\n",
      "train_error: 0.1347, test_error: 0.1085\n",
      "iteration: 200\n",
      "train_loss: 0.01622, test_loss: 0.01734\n",
      "train_error: 0.08465, test_error: 0.08711\n",
      "iteration: 300\n",
      "train_loss: 0.01525, test_loss: 0.01655\n",
      "train_error: 0.06669, test_error: 0.08055\n",
      "iteration: 400\n",
      "train_loss: 0.01252, test_loss: 0.0131\n",
      "train_error: 0.07214, test_error: 0.07148\n",
      "iteration: 500\n",
      "train_loss: 0.005183, test_loss: 0.006682\n",
      "train_error: 0.04815, test_error: 0.05473\n",
      "iteration: 600\n",
      "train_loss: 0.006231, test_loss: 0.008633\n",
      "train_error: 0.05506, test_error: 0.05742\n",
      "iteration: 700\n",
      "train_loss: 0.002313, test_loss: 0.004276\n",
      "train_error: 0.03318, test_error: 0.04426\n",
      "iteration: 800\n",
      "train_loss: 0.003474, test_loss: 0.003067\n",
      "train_error: 0.0409, test_error: 0.03755\n",
      "iteration: 900\n",
      "train_loss: 0.005753, test_loss: 0.004188\n",
      "train_error: 0.05004, test_error: 0.04261\n",
      "iteration: 1000\n",
      "train_loss: 0.001443, test_loss: 0.002223\n",
      "train_error: 0.02657, test_error: 0.03229\n",
      "iteration: 1100\n",
      "train_loss: 0.001414, test_loss: 0.002214\n",
      "train_error: 0.02771, test_error: 0.03161\n",
      "iteration: 1200\n",
      "train_loss: 0.001174, test_loss: 0.001359\n",
      "train_error: 0.02374, test_error: 0.02553\n",
      "iteration: 1300\n",
      "train_loss: 0.002157, test_loss: 0.002181\n",
      "train_error: 0.03286, test_error: 0.03145\n",
      "iteration: 1400\n",
      "train_loss: 0.00158, test_loss: 0.002077\n",
      "train_error: 0.02672, test_error: 0.03052\n",
      "iteration: 1500\n",
      "train_loss: 0.004407, test_loss: 0.003469\n",
      "train_error: 0.04229, test_error: 0.03791\n",
      "iteration: 1600\n",
      "train_loss: 0.001285, test_loss: 0.001489\n",
      "train_error: 0.02414, test_error: 0.02628\n",
      "iteration: 1700\n",
      "train_loss: 0.001645, test_loss: 0.002529\n",
      "train_error: 0.02361, test_error: 0.03203\n",
      "iteration: 1800\n",
      "train_loss: 0.0008078, test_loss: 0.001061\n",
      "train_error: 0.01948, test_error: 0.02184\n",
      "iteration: 1900\n",
      "train_loss: 0.005087, test_loss: 0.006063\n",
      "train_error: 0.04128, test_error: 0.04524\n",
      "iteration: 2000\n",
      "train_loss: 0.001469, test_loss: 0.002132\n",
      "train_error: 0.02674, test_error: 0.02913\n",
      "iteration: 2100\n",
      "train_loss: 0.0004538, test_loss: 0.001719\n",
      "train_error: 0.01403, test_error: 0.02616\n",
      "iteration: 2200\n",
      "train_loss: 0.001232, test_loss: 0.00183\n",
      "train_error: 0.02237, test_error: 0.02763\n",
      "iteration: 2300\n",
      "train_loss: 0.001048, test_loss: 0.00116\n",
      "train_error: 0.02129, test_error: 0.02159\n",
      "iteration: 2400\n",
      "train_loss: 0.0005737, test_loss: 0.0007911\n",
      "train_error: 0.01526, test_error: 0.01872\n",
      "iteration: 2500\n",
      "train_loss: 0.0002353, test_loss: 0.0005509\n",
      "train_error: 0.01121, test_error: 0.01586\n",
      "iteration: 2600\n",
      "train_loss: 0.0003879, test_loss: 0.0005973\n",
      "train_error: 0.01437, test_error: 0.01658\n",
      "iteration: 2700\n",
      "train_loss: 0.0001442, test_loss: 0.0005886\n",
      "train_error: 0.008633, test_error: 0.01587\n",
      "iteration: 2800\n",
      "train_loss: 0.000756, test_loss: 0.001883\n",
      "train_error: 0.01645, test_error: 0.02596\n",
      "iteration: 2900\n",
      "train_loss: 0.002037, test_loss: 0.001411\n",
      "train_error: 0.03054, test_error: 0.02465\n",
      "iteration: 3000\n",
      "train_loss: 0.002343, test_loss: 0.002507\n",
      "train_error: 0.02782, test_error: 0.03005\n",
      "iteration: 3100\n",
      "train_loss: 0.0007811, test_loss: 0.0009632\n",
      "train_error: 0.01865, test_error: 0.01871\n",
      "iteration: 3200\n",
      "train_loss: 0.001033, test_loss: 0.0007635\n",
      "train_error: 0.0178, test_error: 0.01683\n",
      "iteration: 3300\n",
      "train_loss: 0.0006288, test_loss: 0.001209\n",
      "train_error: 0.01882, test_error: 0.02108\n",
      "iteration: 3400\n",
      "train_loss: 0.0003818, test_loss: 0.0008692\n",
      "train_error: 0.01338, test_error: 0.01973\n",
      "iteration: 3500\n",
      "train_loss: 0.000402, test_loss: 0.0005573\n",
      "train_error: 0.01274, test_error: 0.0154\n",
      "iteration: 3600\n",
      "train_loss: 0.0007051, test_loss: 0.001935\n",
      "train_error: 0.01717, test_error: 0.02835\n",
      "iteration: 3700\n",
      "train_loss: 0.0009122, test_loss: 0.001164\n",
      "train_error: 0.0201, test_error: 0.02129\n",
      "iteration: 3800\n",
      "train_loss: 0.005334, test_loss: 0.004916\n",
      "train_error: 0.04704, test_error: 0.03664\n",
      "iteration: 3900\n",
      "train_loss: 0.000529, test_loss: 0.000679\n",
      "train_error: 0.01402, test_error: 0.01645\n",
      "iteration: 4000\n",
      "train_loss: 0.0006474, test_loss: 0.0006748\n",
      "train_error: 0.01736, test_error: 0.01676\n",
      "iteration: 4100\n",
      "train_loss: 0.0005853, test_loss: 0.0007171\n",
      "train_error: 0.01739, test_error: 0.01744\n",
      "iteration: 4200\n",
      "train_loss: 0.0003733, test_loss: 0.000688\n",
      "train_error: 0.01461, test_error: 0.01645\n",
      "iteration: 4300\n",
      "train_loss: 0.01012, test_loss: 0.008606\n",
      "train_error: 0.05505, test_error: 0.04684\n",
      "iteration: 4400\n",
      "train_loss: 0.0009043, test_loss: 0.001709\n",
      "train_error: 0.01904, test_error: 0.02508\n",
      "iteration: 4500\n",
      "train_loss: 0.0004226, test_loss: 0.001225\n",
      "train_error: 0.01438, test_error: 0.02082\n",
      "iteration: 4600\n",
      "train_loss: 0.0003998, test_loss: 0.0007404\n",
      "train_error: 0.01372, test_error: 0.01716\n",
      "iteration: 4700\n",
      "train_loss: 0.0003854, test_loss: 0.000658\n",
      "train_error: 0.01374, test_error: 0.01588\n",
      "iteration: 4800\n",
      "train_loss: 0.0003247, test_loss: 0.0006482\n",
      "train_error: 0.01195, test_error: 0.01659\n",
      "iteration: 4900\n",
      "train_loss: 0.001246, test_loss: 0.001886\n",
      "train_error: 0.02211, test_error: 0.02554\n",
      "iteration: 5000\n",
      "train_loss: 0.0002991, test_loss: 0.0004183\n",
      "train_error: 0.01055, test_error: 0.01261\n",
      "iteration: 5100\n",
      "train_loss: 0.0005683, test_loss: 0.001171\n",
      "train_error: 0.01555, test_error: 0.02015\n",
      "iteration: 5200\n",
      "train_loss: 0.002464, test_loss: 0.002715\n",
      "train_error: 0.03083, test_error: 0.02827\n",
      "iteration: 5300\n",
      "train_loss: 0.0012, test_loss: 0.001817\n",
      "train_error: 0.02285, test_error: 0.02587\n",
      "iteration: 5400\n",
      "train_loss: 0.001917, test_loss: 0.002777\n",
      "train_error: 0.02715, test_error: 0.03185\n",
      "iteration: 5500\n",
      "train_loss: 0.0001354, test_loss: 0.0004289\n",
      "train_error: 0.008712, test_error: 0.01375\n",
      "iteration: 5600\n",
      "train_loss: 0.0002058, test_loss: 0.0003985\n",
      "train_error: 0.009894, test_error: 0.01301\n",
      "iteration: 5700\n",
      "train_loss: 0.0002304, test_loss: 0.0004187\n",
      "train_error: 0.0109, test_error: 0.01277\n",
      "iteration: 5800\n",
      "train_loss: 0.0003866, test_loss: 0.0007094\n",
      "train_error: 0.01329, test_error: 0.01585\n",
      "iteration: 5900\n",
      "train_loss: 0.0001503, test_loss: 0.0003349\n",
      "train_error: 0.008817, test_error: 0.01139\n",
      "iteration: 6000\n",
      "train_loss: 0.001299, test_loss: 0.001154\n",
      "train_error: 0.0218, test_error: 0.01822\n",
      "iteration: 6100\n",
      "train_loss: 0.0007087, test_loss: 0.001017\n",
      "train_error: 0.01808, test_error: 0.01851\n",
      "iteration: 6200\n",
      "train_loss: 0.0003841, test_loss: 0.0007314\n",
      "train_error: 0.0121, test_error: 0.01564\n",
      "iteration: 6300\n",
      "train_loss: 0.0001449, test_loss: 0.0004301\n",
      "train_error: 0.008408, test_error: 0.0122\n",
      "iteration: 6400\n",
      "train_loss: 0.0005716, test_loss: 0.0005081\n",
      "train_error: 0.01568, test_error: 0.01448\n",
      "iteration: 6500\n",
      "train_loss: 0.001853, test_loss: 0.001625\n",
      "train_error: 0.02963, test_error: 0.02448\n",
      "iteration: 6600\n",
      "train_loss: 0.001294, test_loss: 0.001138\n",
      "train_error: 0.02376, test_error: 0.02214\n",
      "iteration: 6700\n",
      "train_loss: 0.0002696, test_loss: 0.0007429\n",
      "train_error: 0.01201, test_error: 0.01604\n",
      "iteration: 6800\n",
      "train_loss: 0.0007624, test_loss: 0.00145\n",
      "train_error: 0.01745, test_error: 0.02248\n",
      "iteration: 6900\n",
      "train_loss: 0.0002273, test_loss: 0.0003751\n",
      "train_error: 0.009795, test_error: 0.01177\n",
      "iteration: 7000\n",
      "train_loss: 0.0002461, test_loss: 0.0007074\n",
      "train_error: 0.0107, test_error: 0.01433\n",
      "iteration: 7100\n",
      "train_loss: 9.965e-05, test_loss: 0.0002948\n",
      "train_error: 0.007492, test_error: 0.01031\n",
      "iteration: 7200\n",
      "train_loss: 0.0001923, test_loss: 0.0005163\n",
      "train_error: 0.009481, test_error: 0.01342\n",
      "iteration: 7300\n",
      "train_loss: 0.000207, test_loss: 0.0003279\n",
      "train_error: 0.009952, test_error: 0.01087\n",
      "iteration: 7400\n",
      "train_loss: 0.0002227, test_loss: 0.0004997\n",
      "train_error: 0.009195, test_error: 0.01298\n",
      "iteration: 7500\n",
      "train_loss: 0.001238, test_loss: 0.001513\n",
      "train_error: 0.02009, test_error: 0.02094\n",
      "iteration: 7600\n",
      "train_loss: 0.0003897, test_loss: 0.0004184\n",
      "train_error: 0.01359, test_error: 0.01328\n",
      "iteration: 7700\n",
      "train_loss: 0.0001677, test_loss: 0.0004375\n",
      "train_error: 0.008723, test_error: 0.01278\n",
      "iteration: 7800\n",
      "train_loss: 0.0002376, test_loss: 0.0004471\n",
      "train_error: 0.01077, test_error: 0.01336\n",
      "iteration: 7900\n",
      "train_loss: 0.0006441, test_loss: 0.001041\n",
      "train_error: 0.01812, test_error: 0.01873\n",
      "iteration: 8000\n",
      "train_loss: 0.000796, test_loss: 0.0008689\n",
      "train_error: 0.01957, test_error: 0.01858\n",
      "iteration: 8100\n",
      "train_loss: 0.0004148, test_loss: 0.0005689\n",
      "train_error: 0.01432, test_error: 0.01384\n",
      "iteration: 8200\n",
      "train_loss: 0.002076, test_loss: 0.002561\n",
      "train_error: 0.02813, test_error: 0.03028\n",
      "iteration: 8300\n",
      "train_loss: 0.0003608, test_loss: 0.0006885\n",
      "train_error: 0.01231, test_error: 0.01627\n",
      "iteration: 8400\n",
      "train_loss: 9.75e-05, test_loss: 0.0003738\n",
      "train_error: 0.007079, test_error: 0.01182\n",
      "iteration: 8500\n",
      "train_loss: 9.5e-05, test_loss: 0.0002952\n",
      "train_error: 0.007271, test_error: 0.009914\n",
      "iteration: 8600\n",
      "train_loss: 0.0002382, test_loss: 0.0004127\n",
      "train_error: 0.01088, test_error: 0.01126\n",
      "iteration: 8700\n",
      "train_loss: 0.0004547, test_loss: 0.0007684\n",
      "train_error: 0.01424, test_error: 0.01721\n",
      "iteration: 8800\n",
      "train_loss: 0.0002081, test_loss: 0.0003212\n",
      "train_error: 0.009845, test_error: 0.01116\n",
      "iteration: 8900\n",
      "train_loss: 0.0002954, test_loss: 0.0004798\n",
      "train_error: 0.01081, test_error: 0.0132\n",
      "iteration: 9000\n",
      "train_loss: 0.0001855, test_loss: 0.0003339\n",
      "train_error: 0.008869, test_error: 0.01104\n",
      "iteration: 9100\n",
      "train_loss: 0.000884, test_loss: 0.000791\n",
      "train_error: 0.01683, test_error: 0.01533\n",
      "iteration: 9200\n",
      "train_loss: 0.0001906, test_loss: 0.0003325\n",
      "train_error: 0.009205, test_error: 0.01142\n",
      "iteration: 9300\n",
      "train_loss: 0.0002341, test_loss: 0.0004932\n",
      "train_error: 0.009589, test_error: 0.01343\n",
      "iteration: 9400\n",
      "train_loss: 0.0007468, test_loss: 0.0008196\n",
      "train_error: 0.01693, test_error: 0.01804\n",
      "iteration: 9500\n",
      "train_loss: 0.001446, test_loss: 0.001372\n",
      "train_error: 0.02461, test_error: 0.02422\n",
      "iteration: 9600\n",
      "train_loss: 0.0006507, test_loss: 0.0008519\n",
      "train_error: 0.01567, test_error: 0.01656\n",
      "iteration: 9700\n",
      "train_loss: 0.0001253, test_loss: 0.000305\n",
      "train_error: 0.007564, test_error: 0.01111\n",
      "iteration: 9800\n",
      "train_loss: 0.0001079, test_loss: 0.0002672\n",
      "train_error: 0.007141, test_error: 0.00952\n",
      "iteration: 9900\n",
      "train_loss: 4.161e-05, test_loss: 0.0002542\n",
      "train_error: 0.004648, test_error: 0.00877\n",
      "iteration: 10000\n",
      "train_loss: 5.576e-05, test_loss: 0.0002218\n",
      "train_error: 0.005413, test_error: 0.008449\n",
      "iteration: 10100\n",
      "train_loss: 0.0001714, test_loss: 0.0003389\n",
      "train_error: 0.008811, test_error: 0.01057\n",
      "iteration: 10200\n",
      "train_loss: 7.476e-05, test_loss: 0.0002488\n",
      "train_error: 0.006307, test_error: 0.009098\n",
      "iteration: 10300\n",
      "train_loss: 0.0002641, test_loss: 0.0007439\n",
      "train_error: 0.009928, test_error: 0.01494\n",
      "iteration: 10400\n",
      "train_loss: 0.0007735, test_loss: 0.001497\n",
      "train_error: 0.01632, test_error: 0.02211\n",
      "iteration: 10500\n",
      "train_loss: 0.001622, test_loss: 0.002211\n",
      "train_error: 0.0271, test_error: 0.02891\n",
      "iteration: 10600\n",
      "train_loss: 0.0002327, test_loss: 0.0004706\n",
      "train_error: 0.009568, test_error: 0.01323\n",
      "iteration: 10700\n",
      "train_loss: 0.0002314, test_loss: 0.0003516\n",
      "train_error: 0.009948, test_error: 0.011\n",
      "iteration: 10800\n",
      "train_loss: 5.894e-05, test_loss: 0.000326\n",
      "train_error: 0.005509, test_error: 0.0101\n",
      "iteration: 10900\n",
      "train_loss: 0.000163, test_loss: 0.0003019\n",
      "train_error: 0.008452, test_error: 0.009864\n",
      "iteration: 11000\n",
      "train_loss: 0.0001315, test_loss: 0.000343\n",
      "train_error: 0.008578, test_error: 0.01042\n",
      "iteration: 11100\n",
      "train_loss: 8.21e-05, test_loss: 0.0002424\n",
      "train_error: 0.006306, test_error: 0.009099\n",
      "iteration: 11200\n",
      "train_loss: 5.208e-05, test_loss: 0.000242\n",
      "train_error: 0.005331, test_error: 0.009052\n",
      "iteration: 11300\n",
      "train_loss: 3.355e-05, test_loss: 0.0002155\n",
      "train_error: 0.00406, test_error: 0.008555\n",
      "iteration: 11400\n",
      "train_loss: 0.0005482, test_loss: 0.0004923\n",
      "train_error: 0.0144, test_error: 0.01233\n",
      "iteration: 11500\n",
      "train_loss: 0.0005286, test_loss: 0.0006287\n",
      "train_error: 0.01455, test_error: 0.01554\n",
      "iteration: 11600\n",
      "train_loss: 0.0008046, test_loss: 0.0005452\n",
      "train_error: 0.01591, test_error: 0.01315\n",
      "iteration: 11700\n",
      "train_loss: 0.001324, test_loss: 0.001851\n",
      "train_error: 0.02168, test_error: 0.02306\n",
      "iteration: 11800\n",
      "train_loss: 0.000481, test_loss: 0.0005101\n",
      "train_error: 0.01267, test_error: 0.01296\n",
      "iteration: 11900\n",
      "train_loss: 0.0001439, test_loss: 0.0003878\n",
      "train_error: 0.008073, test_error: 0.01076\n",
      "iteration: 12000\n",
      "train_loss: 0.0001814, test_loss: 0.0003557\n",
      "train_error: 0.009027, test_error: 0.01079\n",
      "iteration: 12100\n",
      "train_loss: 0.000322, test_loss: 0.0003886\n",
      "train_error: 0.01043, test_error: 0.0117\n",
      "iteration: 12200\n",
      "train_loss: 0.0002519, test_loss: 0.0002982\n",
      "train_error: 0.009742, test_error: 0.01059\n",
      "iteration: 12300\n",
      "train_loss: 0.0003807, test_loss: 0.001102\n",
      "train_error: 0.01247, test_error: 0.01839\n",
      "iteration: 12400\n",
      "train_loss: 0.000121, test_loss: 0.0003706\n",
      "train_error: 0.007036, test_error: 0.01126\n",
      "iteration: 12500\n",
      "train_loss: 0.0006554, test_loss: 0.0007233\n",
      "train_error: 0.01408, test_error: 0.01541\n",
      "iteration: 12600\n",
      "train_loss: 0.005399, test_loss: 0.006051\n",
      "train_error: 0.04056, test_error: 0.04311\n",
      "iteration: 12700\n",
      "train_loss: 0.0004812, test_loss: 0.0008742\n",
      "train_error: 0.01289, test_error: 0.01739\n",
      "iteration: 12800\n",
      "train_loss: 0.0002798, test_loss: 0.0004628\n",
      "train_error: 0.01001, test_error: 0.01266\n",
      "iteration: 12900\n",
      "train_loss: 0.0001403, test_loss: 0.0003925\n",
      "train_error: 0.007477, test_error: 0.01167\n",
      "iteration: 13000\n",
      "train_loss: 7.034e-05, test_loss: 0.0001951\n",
      "train_error: 0.005922, test_error: 0.008402\n",
      "iteration: 13100\n",
      "train_loss: 6.042e-05, test_loss: 0.0001735\n",
      "train_error: 0.005515, test_error: 0.007975\n",
      "iteration: 13200\n",
      "train_loss: 3.15e-05, test_loss: 0.0001726\n",
      "train_error: 0.00389, test_error: 0.008156\n",
      "iteration: 13300\n",
      "train_loss: 0.000169, test_loss: 0.0001983\n",
      "train_error: 0.007648, test_error: 0.008377\n",
      "iteration: 13400\n",
      "train_loss: 0.0001561, test_loss: 0.0006223\n",
      "train_error: 0.00751, test_error: 0.01389\n",
      "iteration: 13500\n",
      "train_loss: 9.687e-05, test_loss: 0.0002432\n",
      "train_error: 0.006497, test_error: 0.009312\n",
      "iteration: 13600\n",
      "train_loss: 0.0001091, test_loss: 0.0001959\n",
      "train_error: 0.006478, test_error: 0.008257\n",
      "iteration: 13700\n",
      "train_loss: 0.0002115, test_loss: 0.0003726\n",
      "train_error: 0.00999, test_error: 0.01205\n",
      "iteration: 13800\n",
      "train_loss: 0.0001782, test_loss: 0.0002644\n",
      "train_error: 0.00911, test_error: 0.01006\n",
      "iteration: 13900\n",
      "train_loss: 6.927e-05, test_loss: 0.000212\n",
      "train_error: 0.006003, test_error: 0.008763\n",
      "iteration: 14000\n",
      "train_loss: 8.686e-05, test_loss: 0.0002218\n",
      "train_error: 0.005995, test_error: 0.008883\n",
      "iteration: 14100\n",
      "train_loss: 0.0003066, test_loss: 0.0004331\n",
      "train_error: 0.01046, test_error: 0.01191\n",
      "iteration: 14200\n",
      "train_loss: 0.0003743, test_loss: 0.0005552\n",
      "train_error: 0.01181, test_error: 0.01564\n",
      "iteration: 14300\n",
      "train_loss: 0.000197, test_loss: 0.0005376\n",
      "train_error: 0.009089, test_error: 0.01334\n",
      "iteration: 14400\n",
      "train_loss: 6.376e-05, test_loss: 0.0002683\n",
      "train_error: 0.00537, test_error: 0.009484\n",
      "iteration: 14500\n",
      "train_loss: 0.000349, test_loss: 0.0007289\n",
      "train_error: 0.01294, test_error: 0.01674\n",
      "iteration: 14600\n",
      "train_loss: 9.868e-05, test_loss: 0.000324\n",
      "train_error: 0.007229, test_error: 0.01159\n",
      "iteration: 14700\n",
      "train_loss: 0.0002031, test_loss: 0.0002976\n",
      "train_error: 0.008836, test_error: 0.01036\n",
      "iteration: 14800\n",
      "train_loss: 0.0001699, test_loss: 0.0002999\n",
      "train_error: 0.008215, test_error: 0.01024\n",
      "iteration: 14900\n",
      "train_loss: 0.0012, test_loss: 0.0009866\n",
      "train_error: 0.01904, test_error: 0.01706\n",
      "iteration: 15000\n",
      "train_loss: 0.0002998, test_loss: 0.0004532\n",
      "train_error: 0.01119, test_error: 0.01309\n",
      "iteration: 15100\n",
      "train_loss: 7.597e-05, test_loss: 0.0002354\n",
      "train_error: 0.006081, test_error: 0.008929\n",
      "iteration: 15200\n",
      "train_loss: 6.739e-05, test_loss: 0.0001674\n",
      "train_error: 0.005208, test_error: 0.007588\n",
      "iteration: 15300\n",
      "train_loss: 5.974e-05, test_loss: 0.0001639\n",
      "train_error: 0.005386, test_error: 0.007752\n",
      "iteration: 15400\n",
      "train_loss: 6.828e-05, test_loss: 0.0001763\n",
      "train_error: 0.00585, test_error: 0.007752\n",
      "iteration: 15500\n",
      "train_loss: 5.178e-05, test_loss: 0.0002002\n",
      "train_error: 0.005161, test_error: 0.008065\n",
      "iteration: 15600\n",
      "train_loss: 0.0001607, test_loss: 0.0002477\n",
      "train_error: 0.007658, test_error: 0.00961\n",
      "iteration: 15700\n",
      "train_loss: 0.0001981, test_loss: 0.0002973\n",
      "train_error: 0.009591, test_error: 0.01041\n",
      "iteration: 15800\n",
      "train_loss: 0.0002846, test_loss: 0.0006319\n",
      "train_error: 0.01127, test_error: 0.01599\n",
      "iteration: 15900\n",
      "train_loss: 0.000467, test_loss: 0.0005533\n",
      "train_error: 0.01419, test_error: 0.01531\n",
      "iteration: 16000\n",
      "train_loss: 0.0006115, test_loss: 0.0009078\n",
      "train_error: 0.01568, test_error: 0.01879\n",
      "iteration: 16100\n",
      "train_loss: 0.001091, test_loss: 0.001246\n",
      "train_error: 0.02108, test_error: 0.0198\n",
      "iteration: 16200\n",
      "train_loss: 6.848e-05, test_loss: 0.0002027\n",
      "train_error: 0.00554, test_error: 0.008597\n",
      "iteration: 16300\n",
      "train_loss: 0.0001357, test_loss: 0.0002604\n",
      "train_error: 0.008067, test_error: 0.009674\n",
      "iteration: 16400\n",
      "train_loss: 5.076e-05, test_loss: 0.0001974\n",
      "train_error: 0.005232, test_error: 0.008374\n",
      "iteration: 16500\n",
      "train_loss: 7.144e-05, test_loss: 0.000171\n",
      "train_error: 0.005905, test_error: 0.007849\n",
      "iteration: 16600\n",
      "train_loss: 7.028e-05, test_loss: 0.0001795\n",
      "train_error: 0.006031, test_error: 0.007655\n",
      "iteration: 16700\n",
      "train_loss: 0.0001277, test_loss: 0.0003843\n",
      "train_error: 0.006921, test_error: 0.01158\n",
      "iteration: 16800\n",
      "train_loss: 0.00115, test_loss: 0.001027\n",
      "train_error: 0.01946, test_error: 0.0173\n",
      "iteration: 16900\n",
      "train_loss: 0.0003051, test_loss: 0.000334\n",
      "train_error: 0.01204, test_error: 0.01106\n",
      "iteration: 17000\n",
      "train_loss: 0.0004422, test_loss: 0.0006858\n",
      "train_error: 0.0135, test_error: 0.01626\n",
      "iteration: 17100\n",
      "train_loss: 0.0002353, test_loss: 0.0003577\n",
      "train_error: 0.009663, test_error: 0.01175\n",
      "iteration: 17200\n",
      "train_loss: 0.0001696, test_loss: 0.0002031\n",
      "train_error: 0.008055, test_error: 0.009097\n",
      "iteration: 17300\n",
      "train_loss: 0.000459, test_loss: 0.0006311\n",
      "train_error: 0.01296, test_error: 0.01498\n",
      "iteration: 17400\n",
      "train_loss: 0.0001969, test_loss: 0.0003904\n",
      "train_error: 0.009497, test_error: 0.01196\n",
      "iteration: 17500\n",
      "train_loss: 5.575e-05, test_loss: 0.0002687\n",
      "train_error: 0.004975, test_error: 0.008964\n",
      "iteration: 17600\n",
      "train_loss: 4.982e-05, test_loss: 0.0001421\n",
      "train_error: 0.004943, test_error: 0.007062\n",
      "iteration: 17700\n",
      "train_loss: 2.346e-05, test_loss: 0.0001335\n",
      "train_error: 0.003511, test_error: 0.006753\n",
      "iteration: 17800\n",
      "train_loss: 3.971e-05, test_loss: 0.0001372\n",
      "train_error: 0.004135, test_error: 0.007016\n",
      "iteration: 17900\n",
      "train_loss: 5.848e-05, test_loss: 0.0001512\n",
      "train_error: 0.005429, test_error: 0.007156\n",
      "iteration: 18000\n",
      "train_loss: 4.209e-05, test_loss: 0.0001405\n",
      "train_error: 0.004309, test_error: 0.006727\n",
      "iteration: 18100\n",
      "train_loss: 9.231e-05, test_loss: 0.0002775\n",
      "train_error: 0.00645, test_error: 0.01013\n",
      "iteration: 18200\n",
      "train_loss: 0.0002144, test_loss: 0.0003691\n",
      "train_error: 0.009874, test_error: 0.01153\n",
      "iteration: 18300\n",
      "train_loss: 4.497e-05, test_loss: 0.0001991\n",
      "train_error: 0.004711, test_error: 0.008602\n",
      "iteration: 18400\n",
      "train_loss: 6.053e-05, test_loss: 0.0002226\n",
      "train_error: 0.005764, test_error: 0.008159\n",
      "iteration: 18500\n",
      "train_loss: 0.0003814, test_loss: 0.0003975\n",
      "train_error: 0.01181, test_error: 0.01229\n",
      "iteration: 18600\n",
      "train_loss: 0.000231, test_loss: 0.0004616\n",
      "train_error: 0.009457, test_error: 0.01187\n",
      "iteration: 18700\n",
      "train_loss: 0.001195, test_loss: 0.001689\n",
      "train_error: 0.02354, test_error: 0.02649\n",
      "iteration: 18800\n",
      "train_loss: 0.000176, test_loss: 0.0003285\n",
      "train_error: 0.009751, test_error: 0.01146\n",
      "iteration: 18900\n",
      "train_loss: 6.038e-05, test_loss: 0.0001889\n",
      "train_error: 0.005635, test_error: 0.008484\n",
      "iteration: 19000\n",
      "train_loss: 3.592e-05, test_loss: 0.000149\n",
      "train_error: 0.004396, test_error: 0.007588\n",
      "iteration: 19100\n",
      "train_loss: 8.379e-05, test_loss: 0.0001744\n",
      "train_error: 0.006007, test_error: 0.008088\n",
      "iteration: 19200\n",
      "train_loss: 9.815e-05, test_loss: 0.0002693\n",
      "train_error: 0.006798, test_error: 0.01079\n",
      "iteration: 19300\n",
      "train_loss: 5.284e-05, test_loss: 0.0001558\n",
      "train_error: 0.005103, test_error: 0.007404\n",
      "iteration: 19400\n",
      "train_loss: 4.914e-05, test_loss: 0.0001453\n",
      "train_error: 0.004738, test_error: 0.007029\n",
      "iteration: 19500\n",
      "train_loss: 4.658e-05, test_loss: 0.0001312\n",
      "train_error: 0.004777, test_error: 0.006848\n",
      "iteration: 19600\n",
      "train_loss: 6.289e-05, test_loss: 0.0001754\n",
      "train_error: 0.0055, test_error: 0.007652\n",
      "iteration: 19700\n",
      "train_loss: 0.0001609, test_loss: 0.0006387\n",
      "train_error: 0.008527, test_error: 0.01258\n",
      "iteration: 19800\n",
      "train_loss: 0.0005138, test_loss: 0.0006708\n",
      "train_error: 0.01381, test_error: 0.01533\n",
      "iteration: 19900\n",
      "train_loss: 6.758e-05, test_loss: 0.0001797\n",
      "train_error: 0.005348, test_error: 0.008024\n",
      "iteration: 20000\n",
      "train_loss: 0.0002572, test_loss: 0.0006015\n",
      "train_error: 0.009732, test_error: 0.01373\n",
      "iteration: 20100\n",
      "train_loss: 0.0003302, test_loss: 0.0004746\n",
      "train_error: 0.01194, test_error: 0.01384\n",
      "iteration: 20200\n",
      "train_loss: 0.000179, test_loss: 0.0002215\n",
      "train_error: 0.008249, test_error: 0.00887\n",
      "iteration: 20300\n",
      "train_loss: 4.659e-05, test_loss: 0.000146\n",
      "train_error: 0.004643, test_error: 0.007298\n",
      "iteration: 20400\n",
      "train_loss: 0.001596, test_loss: 0.001967\n",
      "train_error: 0.02758, test_error: 0.02763\n",
      "iteration: 20500\n",
      "train_loss: 0.0001807, test_loss: 0.0003937\n",
      "train_error: 0.009445, test_error: 0.01218\n",
      "iteration: 20600\n",
      "train_loss: 8.829e-05, test_loss: 0.0002046\n",
      "train_error: 0.006353, test_error: 0.008827\n",
      "iteration: 20700\n",
      "train_loss: 5.667e-05, test_loss: 0.0002006\n",
      "train_error: 0.005142, test_error: 0.007868\n",
      "iteration: 20800\n",
      "train_loss: 2.493e-05, test_loss: 0.0001509\n",
      "train_error: 0.003708, test_error: 0.006699\n",
      "iteration: 20900\n",
      "train_loss: 2.738e-05, test_loss: 0.0001377\n",
      "train_error: 0.00382, test_error: 0.006597\n",
      "iteration: 21000\n",
      "train_loss: 3.046e-05, test_loss: 0.0001602\n",
      "train_error: 0.003808, test_error: 0.00684\n",
      "iteration: 21100\n",
      "train_loss: 1.984e-05, test_loss: 0.0001611\n",
      "train_error: 0.003287, test_error: 0.007025\n",
      "iteration: 21200\n",
      "train_loss: 3.486e-05, test_loss: 0.0001252\n",
      "train_error: 0.004112, test_error: 0.006704\n",
      "iteration: 21300\n",
      "train_loss: 3.234e-05, test_loss: 0.0001446\n",
      "train_error: 0.003951, test_error: 0.007205\n",
      "iteration: 21400\n",
      "train_loss: 1.92e-05, test_loss: 0.0001302\n",
      "train_error: 0.003042, test_error: 0.006845\n",
      "iteration: 21500\n",
      "train_loss: 5.028e-05, test_loss: 0.0002162\n",
      "train_error: 0.004667, test_error: 0.008422\n",
      "iteration: 21600\n",
      "train_loss: 0.0001448, test_loss: 0.0003386\n",
      "train_error: 0.007789, test_error: 0.01079\n",
      "iteration: 21700\n",
      "train_loss: 0.0001078, test_loss: 0.0002438\n",
      "train_error: 0.006703, test_error: 0.009619\n",
      "iteration: 21800\n",
      "train_loss: 8.949e-05, test_loss: 0.0002029\n",
      "train_error: 0.00689, test_error: 0.009054\n",
      "iteration: 21900\n",
      "train_loss: 0.0004681, test_loss: 0.000545\n",
      "train_error: 0.01407, test_error: 0.01502\n",
      "iteration: 22000\n",
      "train_loss: 0.0004876, test_loss: 0.0008367\n",
      "train_error: 0.01497, test_error: 0.01745\n",
      "iteration: 22100\n",
      "train_loss: 4.633e-05, test_loss: 0.0001925\n",
      "train_error: 0.004741, test_error: 0.008364\n",
      "iteration: 22200\n",
      "train_loss: 5.574e-05, test_loss: 0.0001991\n",
      "train_error: 0.004506, test_error: 0.00816\n",
      "iteration: 22300\n",
      "train_loss: 6.014e-05, test_loss: 0.0001405\n",
      "train_error: 0.005358, test_error: 0.007167\n",
      "iteration: 22400\n",
      "train_loss: 2.859e-05, test_loss: 0.0001329\n",
      "train_error: 0.003888, test_error: 0.006902\n",
      "iteration: 22500\n",
      "train_loss: 2.332e-05, test_loss: 0.0001307\n",
      "train_error: 0.003335, test_error: 0.006346\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     40\u001b[0m loss_train\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 41\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    408\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 410\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    412\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d0c4a-1fb9-4c98-b3c7-dc5797b5e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过拟合\n",
    "# MSEloss curve\n",
    "Len = len(losses['loss_train'])\n",
    "epoch_total = np.linspace(0, Len, Len)\n",
    "plt.title('MSEloss')\n",
    "plt.plot(epoch_total, losses['loss_train'],color=\"black\", label='Train_loss')\n",
    "plt.plot(epoch_total, losses['loss_test'],color=\"orange\", label='Train_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch_total')\n",
    "plt.ylabel('loss_fn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b63d77-41ab-4721-8cea-3292e70305b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train or test\n",
    "bo_len = np.loadtxt(bo_len_path, delimiter=\",\", dtype=np.float32)\n",
    "\n",
    "# plot_train_data\n",
    "c = 3\n",
    "valid_input = train_input[c:c+1]\n",
    "valid_predict = forward_model(valid_input).view(-1).cpu().detach().numpy().reshape(1, 300)               \n",
    "valid_label = train_label[c].cpu().detach().numpy().reshape(1, 300)                                    \n",
    "valid_predict = valid_predict.reshape(300,)\n",
    "valid_label = valid_label.reshape(300,)\n",
    "print(valid_input)\n",
    "\n",
    "plt.title('Comparison of Transmission Spectrum')\n",
    "plt.plot(bo_len, valid_predict, color=\"orange\", label='Prediction', linestyle='-')\n",
    "plt.plot(bo_len, valid_label, color=\"black\", label='Simulation', linestyle=':')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Fx(10^-12)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58239de7-e6c9-4d16-865b-d8cd9560899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9560c-a13f-4343-ad69-3fbd7faed9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试及画图\n",
    "c = 36                              # 36\n",
    "valid_input = test_input[c:c+1]\n",
    "print(valid_input)\n",
    "valid_predict = forward_model(valid_input).view(-1).cpu().detach().numpy().reshape(1, 300)               \n",
    "valid_label = test_label[c].cpu().detach().numpy().reshape(1, 300)                                    \n",
    "valid_predict = valid_predict.reshape(300,)\n",
    "valid_label = valid_label.reshape(300,)\n",
    "\n",
    "plt.title('Comparison of Transmission Spectrum')\n",
    "plt.plot(bo_len, valid_predict, color=\"orange\", label='Prediction', linestyle='--')\n",
    "plt.plot(bo_len, valid_label, color=\"black\", label='Simulation', linestyle=':')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Fx(10^-12)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad56653-b40a-4201-8535-b60ca80ec2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated weights file\n",
    "save_dir = os.path.join(data_root, \"weight_optim\")\n",
    "assert os.path.exists(save_dir), \"{} path does not exist.\".format(save_dir)\n",
    "# Save the weight_optim\n",
    "torch.save(forward_model, save_dir + '\\model_train_Fy'  + '.pth')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25df9535-55ed-4e40-92fd-95f377151f09",
   "metadata": {},
   "source": [
    "# 数据补充保存--测试集c=36的数据\n",
    "test_36 = np.zeros((300, 3))\n",
    "test_36[:, 0] = bo_len\n",
    "test_36[:, 1] = valid_label        # 真实值\n",
    "test_36[:, 2] = valid_predict      # 预测值\n",
    "np.savetxt(\"Fy.csv\", test_36, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9ce55-2df7-4f00-a9ea-88481b9f2cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
